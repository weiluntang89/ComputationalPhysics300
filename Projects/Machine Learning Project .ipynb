{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e69c6a1",
   "metadata": {},
   "source": [
    "# Final Project: Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb57fbc",
   "metadata": {},
   "source": [
    "## Weilun Tang "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a356082",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdd395",
   "metadata": {},
   "source": [
    "A machine learning algorithm is a computational process that uses input data to achieve a desired task without being literally programmed to produce a particular outcome. The algorithm learns from the data and adapt themselves from their experience in order to achieve their task better. The process of adaptation is called training. The process of the machine learning from the data is identical to how human being learn. \n",
    "\n",
    "There are two types of learning, unsupervised learning and supervised learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19cd6a8",
   "metadata": {},
   "source": [
    "## Supervised Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baad0f6",
   "metadata": {},
   "source": [
    "Unsupervised learning is the algorithms that discover the patterns without any human intervention. By contrast, supervised learning is to use labeled datasets to train the algorithms in order to classify data or predict outcomes accurately. There are two types of problems in supervised learning, classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5e727",
   "metadata": {},
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74674092",
   "metadata": {},
   "source": [
    "Classfication is to use the algorithm to assign test data into specific categories. The test data is used to train the machine, and it will recognize the pattern and label data in appropriate class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb53068",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae201d3",
   "metadata": {},
   "source": [
    "Regression is to use the algorithm to understand the relationship between dependent and independent variables. It is often used in business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed1cac",
   "metadata": {},
   "source": [
    "# Bias and Variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314acda",
   "metadata": {},
   "source": [
    "In machine learning, bias is the inability of the estimation to represent the true relationship of the data. If the estimation is high biased, the estimation does not show the true relationship well. By contrast, the estimation show the true relationship well if the estimation is low bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fbada",
   "metadata": {},
   "source": [
    "![](bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef0793",
   "metadata": {},
   "source": [
    "In the figure above, the machine learning algorithms for the same dataset are linear regression and squiggly line. In the linear regression, the distance from the data points to the straight line is relatively large compared to the squiggly line. The straight line is high bias, and the squiggly line is low bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672ea17",
   "metadata": {},
   "source": [
    "Variance is the difference in fits between data sets. If the linear regression and the squiggly line are used for another data set as it is shown in the figure below. The distance from the data points to the straight line is relatively the same compared to the last data. However, the distace from the data points to the squiggly line increases significantly. This example shows that the straight line has low variance. The low varibility shows that the sum of the squares is relatively the same for every data set. By contrast, the squiggly line has high variance. The high varibility shows that the sum of the squares varies significantly between data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321a1c0",
   "metadata": {},
   "source": [
    "![](variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc007d",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce452f1",
   "metadata": {},
   "source": [
    "## Basic Idea of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dd3a3",
   "metadata": {},
   "source": [
    "Support-vector machines (SVMs) are the most commonly used supervised learning models for classification. The method is to generate some hyperplanes in order to classify data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341104d",
   "metadata": {},
   "source": [
    "![](svmimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a4ca4",
   "metadata": {},
   "source": [
    "Consider the image above, the blue colored diamonds and green circles are two classes. There is a black solid line that seperates two classes. This line is called the hyperplane. By definition, a hyperplane is a subspace whose dimension is one less than that of its ambient space. In this example, the two classes of data are 2-dimensional. The black solid line is 1-dimensional. Thus, the line is the hyperplane for this data set. The shortest distance from a data point of a class to the hyperplane is called the maximum margin, so the hyperplane is called the maximal margin classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78defc",
   "metadata": {},
   "source": [
    "The position of the hyperplane is not usually determined by the maximum margin. Consider a case that one of the class has an outlier as it is shown below "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7cea3",
   "metadata": {},
   "source": [
    "![](svmOutlier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ab696",
   "metadata": {},
   "source": [
    "The blue stars and red circles are two classes, and they are showing in a 2-dimensional plane. The class of blue stars has an outlier, and it is near the class of red circles. If the hyperplane is placed in the middle as the figure above, it is difficult to classify if a new data point is on the right side of the hyperplane. If maximal margin classifier is used in this case, the majority of the blue stars is far away from the classifier. Therefore, the maximal margin classifier is sensitive to the outlier. The sensitivity of the maximal margin classifier shows that the classifier is low bias but high variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb222a0",
   "metadata": {},
   "source": [
    "The solution to this problem is to allow misclassification. Place the hyperplane as it is shown in the figure above. The outlier of the blue stars is the misclassifications. However, if there is a new data point on the right side of the hyperplane, it is classified as the red circle class. When misclassifications are allowed, the distance between the data to the hyperplane is now called a soft margin. The hyperplane is called the soft margin classifier. Moreover, the soft margin classifier is also called as support vector classifier. The data points on the edge of the soft margin is called support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9a929",
   "metadata": {},
   "source": [
    "## Hinge Loss Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c782b",
   "metadata": {},
   "source": [
    "Loss function is usually used for measuring the loss of a specific model. Loss function is also called the cost function or error function. It shows that how well the data fits the model. Sum of the squares is one of the common error functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258020da",
   "metadata": {},
   "source": [
    "Hinge loss function is commonly used for SVM. The visualization of a Hinge loss function is shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a9793",
   "metadata": {},
   "source": [
    "![](hinge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711c847",
   "metadata": {},
   "source": [
    "The x-axis is the numbers of the data. The negative direction of the x-axis is when the model incorrectly classified the data, the positive direction of the x-axis is when the model correctly classified the model. The y-axis is the loss size or error. The dash line is at when x = 1. In x > 1 region, all of the data is correctly classified. In x < -1 region, all of the data is incorrectly classified with some losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383f356",
   "metadata": {},
   "source": [
    "# Mathematical Background "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36330b",
   "metadata": {},
   "source": [
    "## Decision Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad9efc",
   "metadata": {},
   "source": [
    "![](svmVectorImage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07245636",
   "metadata": {},
   "source": [
    "Consider a vector $\\vec{w}$ that is normal to the hyperplane. An unknown vector $\\vec{u}$ is an arbitrary vector. In the figure above, the unknown vector u is placed on the left side of the hyperplane. In order to classify an unknown vector, a decision rule needs to be introduced. Take the dot product of vectors $\\vec{u}$ and $\\vec{w}$. The dot product is just the projection of vector u onto vector w. The dot product is equal or greater than some constant b. The equation becomes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c3829",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec{w} \\cdot \\vec{u} \\geq - b\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{w} \\cdot \\vec{u} + b \\geq 0 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d1d1d",
   "metadata": {},
   "source": [
    "This is the decision rule whether the unknow vector is on the right side of the hyperplane. The decision rule can be used to classify whether the sample is a positve or negative sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0f6ce",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec{w} \\cdot \\vec{x_+} + b \\geq 1\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{w} \\cdot \\vec{x_-} + b \\leq 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3bb296",
   "metadata": {},
   "source": [
    "where $\\vec{x_+}$ is the positive sample vector and $\\vec{x_-}$ is the negative sample vector. The equation $\\vec{w} \\cdot \\vec{x_+} + b \\pm 1$ is the equation of the two gutters. \n",
    "\n",
    "It is more convenient to introduce a new variable to turn these two equations into one equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aeac1b",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y_i = 1 for + sample\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = -1 for - sample\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e518bb",
   "metadata": {},
   "source": [
    "Multiply the new variable $y_i$ to the two equations above to get "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2aa62",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y_i (\\vec{w} \\cdot \\vec{x_+} + b) \\geq 1 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077e22d",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y_i (\\vec{w} \\cdot \\vec{x_-} + b) \\geq 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e3b3e",
   "metadata": {},
   "source": [
    "It turns out that the two equations are the same. Write them with the same index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f97d7",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y_i (\\vec{w} \\cdot \\vec{x_i} + b) - 1 \\geq 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3dc1d",
   "metadata": {},
   "source": [
    "Moreover, when this equation is equal to 0, it is for the sample that it is in the gutters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dab28d",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y_i (\\vec{w} \\cdot \\vec{x_i} + b) - 1 = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97946e2",
   "metadata": {},
   "source": [
    "## Width of the Street "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90edf35",
   "metadata": {},
   "source": [
    "![](svmStreet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d9124",
   "metadata": {},
   "source": [
    "Consider a positive and negative sample vectors that are in the gutters. The difference of these two vectors are $\\vec{x_+} - \\vec{x_-}$. If there is a unit vector $\\hat w$ that is normal to the hyperplane, the dot product of the seperation vector and the unit vector $(\\vec{x_+} - \\vec{x_-}) \\cdot \\hat w$ is the width of the street."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735264ce",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "width = (\\vec{x_+} - \\vec{x_-}) \\cdot \\frac{\\vec{w}}{|\\vec{w}|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214aa1c",
   "metadata": {},
   "source": [
    "Use equation $y_i (\\vec{w} \\cdot \\vec{x_i} + b) - 1 = 0$ to find an expression for the postive and negative samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247a2f3",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec{x_+} = 1 - b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44c8be",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "-\\vec{x_-} = 1 + b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6e5be",
   "metadata": {},
   "source": [
    "The final equation of the width becomes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494c011",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "width = \\frac{2}{|\\vec{w}|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d19e4a",
   "metadata": {},
   "source": [
    "In svm, the hyperplane is placed in where the width of the street is maximum. The maximization of the width can be simplify further to minimize the function $\\frac{1}{2} |\\vec{w}|^2$. This function has a constraint such that $y_i (\\vec{w} \\cdot \\vec{x_i} + b) - 1 = 0$. Therefore, this is an optimizing problem with a constraint. The method to solve this is the Lagrange multiplier. The Lagrangian can be written as "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba90bc1",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\frac{1}{2}|\\vec{w}|^2 - \\sum \\alpha_i [y_i (\\vec{w} \\cdot \\vec{x_i} + b) - 1]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0afedc",
   "metadata": {},
   "source": [
    "Take the partial derivative with respect to the variables and set it equal to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4734a1",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial \\vec{w}} = \\vec{w} - \\sum \\alpha_i y_i \\vec{x_i} = 0 \\\\\n",
    "\\vec{w} = \\sum \\alpha_i y_i \\vec{x_i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b6cdc",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial b} = \\sum \\alpha_i y_i = 0 \\\\\n",
    "\\sum \\alpha_i y_i = 0 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5223899",
   "metadata": {},
   "source": [
    "Substitute the results from the partial derivative back to the Lagrangian to get "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6194",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\frac{1}{2} (\\sum_{i} \\alpha_i y_i \\vec{x_i}) (\\sum_{j} \\alpha_j y_j \\vec{x_j}) - (\\sum_{i} \\alpha_i y_i \\vec{x_i}) (\\sum_{j} \\alpha_j y_j \\vec{x_j}) - \\sum_{i} \\alpha_i y_i b_i + \\sum_{i} \\alpha_i \\\\\n",
    "L = \\sum_{i} \\alpha_i - \\frac{1}{2} \\sum_{i} \\sum_{j} \\alpha_i \\alpha_j y_i y_j \\vec{x_i} \\cdot \\vec{x_j}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48d8e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized a step\n",
      "optimized a step\n",
      "optimized a step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 8.71590000000112)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing some basic libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "class SVM(object):\n",
    "    def __init__(self,visualization=True):                #Dunder method, double underscores.\n",
    "        self.visualization = visualization                #Define an attribute \n",
    "        self.colors = {1:'r',-1:'b'}                      #Define an attribute \n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    \n",
    "    def fit(self,data):\n",
    "        #train with data\n",
    "        self.data = data\n",
    "        # { |\\w\\|:{w,b}}\n",
    "        opt_dict = {}\n",
    "        \n",
    "        transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "        \n",
    "        all_data = np.array([])\n",
    "        for yi in self.data:\n",
    "            all_data = np.append(all_data,self.data[yi])    #Store data in a numpy array\n",
    "                    \n",
    "        self.max_feature_value = max(all_data)              #Max value of data \n",
    "        self.min_feature_value = min(all_data)              #Min Value of data \n",
    "        all_data = None\n",
    "        \n",
    "        #with smaller steps our margins and db will be more precise\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      #point of expense\n",
    "                      self.max_feature_value * 0.001,]\n",
    "        \n",
    "        #extremly expensise\n",
    "        b_range_multiple = 5\n",
    "        #we dont need to take as small step as w\n",
    "        b_multiple = 5\n",
    "        \n",
    "        latest_optimum = self.max_feature_value*10\n",
    "        \n",
    "        \"\"\"\n",
    "        objective is to satisfy yi(x.w)+b>=1 for all training dataset such that ||w|| is minimum\n",
    "        for this we will start with random w, and try to satisfy it with making b bigger and bigger\n",
    "        \"\"\"\n",
    "        #making step smaller and smaller to get precise value\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            \n",
    "            #we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*self.max_feature_value*b_range_multiple,\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        \n",
    "                        #weakest link in SVM fundamentally\n",
    "                        #SMO attempts to fix this a bit\n",
    "                        # ti(xi.w+b) >=1\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b)>=1:\n",
    "                                    found_option=False\n",
    "                        if found_option:\n",
    "                            \"\"\"\n",
    "                            all points in dataset satisfy y(w.x)+b>=1 for this cuurent w_t, b\n",
    "                            then put w,b in dict with ||w|| as key\n",
    "                            \"\"\"\n",
    "                            opt_dict[np.linalg.norm(w_t)]=[w_t,b]\n",
    "                \n",
    "                #after w[0] or w[1]<0 then values of w starts repeating itself because of transformation\n",
    "                #Think about it, it is easy\n",
    "                #print(w,len(opt_dict)) Try printing to understand\n",
    "                if w[0]<0:\n",
    "                    optimized=True\n",
    "                    print(\"optimized a step\")\n",
    "                else:\n",
    "                    w = w-step\n",
    "                    \n",
    "            # sorting ||w|| to put the smallest ||w|| at poition 0 \n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #optimal values of w,b\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "\n",
    "            self.w=opt_choice[0]\n",
    "            self.b=opt_choice[1]\n",
    "            \n",
    "            #start with new latest_optimum (initial values for w)\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "    \n",
    "    def predict(self,features):\n",
    "        #sign(x.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification!=0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*',c=self.colors[classification])\n",
    "        return (classification,np.dot(np.array(features),self.w)+self.b)\n",
    "    \n",
    "    def visualize(self):\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,c=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        \n",
    "        # hyperplane = x.w+b (actually its a line)\n",
    "        # v = x0.w0+x1.w1+b -> x1 = (v-w[0].x[0]-b)/w1\n",
    "        #psv = 1     psv line ->  x.w+b = 1a small value of b we will increase it later\n",
    "        #nsv = -1    nsv line ->  x.w+b = -1\n",
    "        # dec = 0    db line  ->  x.w+b = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            #returns a x2 value on line when given x1\n",
    "            return (-w[0]*x-b+v)/w[1]\n",
    "       \n",
    "        hyp_x_min= self.min_feature_value*0.9\n",
    "        hyp_x_max = self.max_feature_value*1.1\n",
    "        \n",
    "        # (w.x+b)=1\n",
    "        # positive support vector hyperplane\n",
    "        pav1 = hyperplane(hyp_x_min,self.w,self.b,1)\n",
    "        pav2 = hyperplane(hyp_x_max,self.w,self.b,1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[pav1,pav2],'k')\n",
    "        \n",
    "        # (w.x+b)=-1\n",
    "        # negative support vector hyperplane\n",
    "        nav1 = hyperplane(hyp_x_min,self.w,self.b,-1)\n",
    "        nav2 = hyperplane(hyp_x_max,self.w,self.b,-1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nav1,nav2],'k')\n",
    "        \n",
    "        # (w.x+b)=0\n",
    "        # db support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min,self.w,self.b,0)\n",
    "        db2 = hyperplane(hyp_x_max,self.w,self.b,0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2],'y--')\n",
    "        \n",
    "        \n",
    "#data \n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "combined = np.vstack((X[:100,2], X[:100,3])).T\n",
    "\n",
    "#print(dataset.feature_names)\n",
    "#print(X[:100,2])\n",
    "#print(len(X[:100,2]))\n",
    "#print(X[:100,3])\n",
    "#plt.scatter(X[:100,2], X[:100,3])\n",
    "\n",
    "#defining a basic data\n",
    "#data_dict = {-1:np.array([[1,0]]), 1:np.array([[3,4]])}\n",
    "\n",
    "data_dict = {-1:combined[0:50],1:combined[50:100]} \n",
    "\n",
    "svm = SVM() # Linear Kernel\n",
    "svm.fit(data=data_dict)\n",
    "svm.visualize()\n",
    "\n",
    "svm.predict([3,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bdb23d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n",
      "50\n",
      "[[4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "#print(dataset.feature_names)\n",
    "#print(X[:100,2])\n",
    "#print(len(X[:100,2]))\n",
    "#print(X[:100,3])\n",
    "plt.scatter(X[:100,2], X[:100,3])\n",
    "\n",
    "#print(np.asarray(X[:100,2]))\n",
    "#print(np.asarray(X[:100,3]))\n",
    "#print(np.array([1,0]))\n",
    "\n",
    "#{-1:np.array([[1.4,1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4,\n",
    "# 1.7, 1.5, 1.7, 1.5, 1.,  1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2,\n",
    "# 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4.,\n",
    "# 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.,  4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.,\n",
    "# 4.9, 4.7, 4.3, 4.4, 4.8, 5.,  4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.,\n",
    "# 4.4, 4.6, 4.,  3.3, 4.2, 4.2, 4.2, 4.3, 3.,  4.1]]),1:np.array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3,\n",
    "# 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2,\n",
    "# 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3,\n",
    "# 1.5, 1.3, 1.6, 1.,  1.3, 1.4, 1.,  1.5, 1.,  1.4, 1.3, 1.4, 1.5, 1.,  1.5, 1.1, 1.8, 1.3,\n",
    "# 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.,  1.1, 1.,  1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3,\n",
    "# 1.2, 1.4, 1.2, 1.,  1.3, 1.2, 1.3, 1.3, 1.1, 1.3]])} \n",
    "combined = np.vstack((X[:100,2], X[:100,3])).T\n",
    "print(combined[0:50])\n",
    "print(len(combined[0:50]))\n",
    "print(combined[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843a773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6954f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
